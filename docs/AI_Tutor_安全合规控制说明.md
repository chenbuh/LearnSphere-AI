# AI Tutor 安全与内容合规控制说明

## 📋 功能概述

为了确保 LearnSphere AI 平台的健康与合规性，我们为 AI 助教功能集成了多层次的安全过滤机制。当用户输入涉及违法、违规、暴力、色情或政治敏感内容时，系统将自动拦截并给予提示，而不会调用 AI 生成任何内容。

## 🔐 安全机制

### 1. 关键词过滤 (DFA 算法)
- **实现方案**：通过后端 `CheckSensitiveAspect` 切面拦截所有带 `@CheckSensitive` 注解的 AI 请求。
- **过滤库**：在数据库 `sensitive_word` 表中维护了丰富的敏感词库，涵盖 30+ 种违法违规类别。
- **拦截逻辑**：一旦命中，直接抛出 403 业务异常，阻止 AI 接口的后续逻辑。

### 2. 前端合规提示
- **交互逻辑**：当接口返回 403 错误（包含敏感词）时，前端 `AITutor.vue` 会捕获该错误。
- **UI 表现**：在对话窗口中以 AI 导师的身份发出 `🚨内容合规提示`，引导用户进行合规学习。
- **状态流转**：此过程不会消耗用户 AI 配额，且不会进入 AI 正在输入的等待状态。

### 3. 系统级提示词约束 (LLM Guard)
- **提示词注入**：在 `AI_TUTOR_SYSTEM` 全局提示词中明确要求 AI 扮演合规教育助教。
- **回答规范**：在 `AI_TUTOR_ADVICE_RULES` 中强制要求回答必须正面、健康。

## 🛠️ 配置说明

### 如何添加新的敏感词
管理员可以直接在数据库 `sensitive_word` 表中插入新词条。每次系统重启时会重新加载词库。

### 拦截提示语修改
修改 `CheckSensitive` 注解的 `message` 属性或直接在 `AITutor.vue` 的错误处理逻辑中调整文本。

## 🧪 测试建议
在 AI 助教输入框中尝试输入预设的敏感词（如“毒品”、“炸药”等），观察系统是否能准确拦截并弹出加红的合规提示语。
